%___________________________________________________________________________________________________
\chapter{Operations with vectors and matrices}    \label{chap:matrices}


\vspace{-.7cm}
\section{Introduction}

This chapter covers two independent topics through examples. 
In the first place, some essential operations of matrix arithmetic are introduced, 
an operation like the product of two matrices becomes extremely simple 
in programming languages oriented to vector programming. 
In the second place, the concepts of static and dynamic data objects are covered. 
Notice that all the examples are written according to a declarative programming style, 
consider reproducing the same results with an imperative programming style to compare.
    
    \vspace{-.3cm}
    \subsection*{Matrix arithmetic}
    \vspace{-.2cm}

An array programming language or vector language has the possibility 
to operate a whole group of values at once.
The common operations that range over scalar numbers can then be applied to vectors, 
matrices and higher dimension arrays in a closer to maths style. 
Hence, mathematical expressions at the time of programming are simplified.

Languages like Fortran, MATLAB, R or the NumPy extension of Python support array programming.
Matrix arithmetic are built-in in these languages and expressing the mathematical language in a natural way is feasible.

\newpage
The following array operations are covered:
\begin{enumerate}
    \item Addition. 
    \item Dot product.
    \item Matrix multiplications. 
    \item Hadamard product. 
\end{enumerate}  


%Take note of the difference between array programming and array processors. The first makes reference to how the programmer 
%codes the mathematical operations in its program (a big advantage is obtained from this feature for Scientific Computing as mentioned before). 
%The second feature is related to how the processor operates that group of numbers, by performing
%all the operations together under the same instruction given to the processor in a considerably increase of speed.
%Both features suppose an increase of performance for the coding and executing of scientific programs, however, this chapter is 
%oriented to the aspects of the first feature mentioned. 



    \vspace{-.5cm}
    \subsection*{Static/Dynamic data objects}

Each data object declared in a program (variables, constants, pointers, arrays, etc.) are either static or dynamic, 
this means that the memory storage to hold that piece of data is reserved during compilation time or 
during the execution of the program respectively. 

Consider for example the Fortran variable \texttt{real :: A(N, N)} declared at the beginning of a code, 
its memory storage is reserved when the program is compiled and this space is not liberated 
until the program has finished the execution. 

Another option to declare and manage the memory storage of an object involves using dynamic allocation. 
In this case, the storage of the variable is not reserved until the program orders it (which happens during the execution of the code) and can be changed or freed at any moment. 
In Fortran for example, this is done through a code like \texttt{real, allocatable :: Ak(:, :, :)}.

This chapter also includes a review of the main memories that a program uses: Static, Heap and Stack.
All variables, program instructions, constants, etc. are stored in these memories and their use is intimately related 
to the different ways of allocating space in the code.



%___________________________________________________________________________________________________
\newpage 
\section{Static size vectors and matrices} 

Consider the same vectors $V, W \in \mathbb{R}^N$ and matrices $A, B \in { \cal{M}}_{N \times N} (\mathbb{R})$ used in previous chapters (with $N=10$): 
$$
V = \left[ v_i =\frac{1}{i^2}, \ \ i = 1 \ldots  N \right],
$$
$$
W = \left[ w_i = \frac{(-1)^{i+1}}{2i+1}, \ \ i = 1 \ldots  N \right].
$$
$$
A = \left[ a_{ij} = \left( \frac{i}{N} \right)^{j-1}, \ \ i = 1 \ldots  N, \ \ j = 1 \ldots  N \right].
$$
$$
B = A^T
$$

and let's compute the following operations:
$$
1.\;\sum_{i=1}^N v_i  \qquad \qquad 2.\;\sum_{i,j=1}^N a_{ij}   \qquad \qquad   3.\;\sum_{v_i>0} v_i   \qquad \qquad 4.\;\sum_{\scriptstyle i,j=1 \atop \scriptstyle a_{ij} > 0.1}^N a_{ij}   
$$
$$
5.\; V\cdot W^T    \quad \quad      6.\; V\cdot (a_{ij})_{\scriptstyle 1\leq i\leq N \atop \scriptstyle j = N}    \quad  \quad  7.\; AV     \quad \quad   8.\;\sum_{i,j=1}^N (A^2)_{ij}   \quad \quad    9.\; B = A^T
$$

$$
10.\;\max_{1\leq i,j\leq N} \{ a_{ij} \}       \qquad \qquad     11.\;\arg\max_{1\leq i,j\leq N} \{ a_{ij} \}   
$$

Since the sizes of these arrays are known at compile-time, the memory storage can be declared statically. 
The main properties of a static allocation are:

\begin{enumerate}
    \item The memory address and the size are assigned during the compilation of the code in the executable image of the program.
    \item These address and size can not be changed during execution.
    \item Once the program finishes the execution the space is freed.
    \item It is a simple and quick allocation process.
\end{enumerate}







        \newpage
        \subsection*{Fortran code}
The following code computes these operations using Fortran. 
Notice that these examples are limited to numeric arrays: integers, reals or complex,
however, arrays can be constructed with a different data type. 
Furthermore, new operations could be defined for other data types. 
    
Consult the specifications of the following matrix operations to become familiarized with the purpose, inputs and arguments.
Notice that the rank and dimension of the arguments must agree with the mathematical definitions of the operations.
As a quick reference: 
\begin{itemize}[noitemsep]
    \item \texttt{sum} adds all elements of an array: across one dimension, all the dimensions 
    or only the elements that accomplish with some condition (e.g. $v_i > 0$).
    \item \texttt{dot\_product} calculates the scalar product of two vectors.
    \item \texttt{matmul} computes a matrix multiplication. 
    \item \texttt{transpose} calculates the transpose of a matrix or vector. 
    \item \texttt{maxval} and \texttt{maxloc} return the maximum value from all the elements of an array and its position respectively.
    It can compute the result across one dimension, the whole array or only for those values that accomplish with a specified condition.
\end{itemize}

\lstfor
\renewcommand{\home}{./Fortran/sources/Foundations/Algebra} 
\listings{\home/Matrix_operations.f90}{subroutine Matrix_operation_examples}
      {end subroutine}{Matrix_operations.f90}

Let's remark some interesting notes of this code. 
First of all, \texttt{N} (which declares the size of the arrays) is declared as a named constant thanks to the \texttt{parameter} attribute. 
Hence, its value is fixed during the whole execution and a try to change it returns a compilation error. 

Secondly, to initialize both \texttt{V} and \texttt{W} their definition is written by means of an implicit loop (declared with parentheses). 
To define the matrix \texttt{A} two implicit loops are used: 
the nested loop \texttt{i} iterates in the rows while 
\texttt{j} jumps from one column to the next one. 
Both loops define a $N*N$ rank-one vector that needs to be reshaped to a ${\mathbb{R}}^{N\times N}$ matrix. 
The function \texttt{reshape} organizes the components of the vector into columns. 

Finally, notice how an implicit loop with a colon symbol \texttt{:} is also used
in the scalar product of the vector \texttt{V} with the $N$-th column of \texttt{A}. 
The implicit loop in \texttt{A} iterates in the \texttt{N} elements of the column. 
Another example would be how the matrix \texttt{B} is written in the screen,
it uses two loops (one explicit and one implicit) so each row of the matrix is represented element by element.
Compare this way with the output of the line \texttt{write(*,*) B} where all the elements are represented by columns and not by rows. 
This is due to the fact multidimensional arrays are stored in a linear storage and Fortran,
which is a \textit{column-major order} language, organizes the consecutive elements of a column one next to each other.






 
%Thirdly, take into account the difference between these operations and the element wise operations that can performed with 
%vectors and matrices. Some operations like the addition of two matrices are performed by adding the corresponding elements of both, also, 
%many elemental operations on numbers can also be applied to matrices, so the result is an equal shaped array 
%with the results of applying the operation to each element. Test the following expressions for matrix addition, Hadamard product (multiplying the corresponding elements of both matrices), cosine or square root of all elements of \texttt{A}:
%
%\begin{verbatim} 
%A + B
%A*B
%cos( A )
%SQRT( A )
%\end{verbatim}




%my matmul







         \newpage 
        \subsection*{Python code}
The same function can be written almost identically with Python. 
Notice from the following code how all vectors and matrices are constructed by using similar implicit loops. 
In addition, the same intrinsic functions are implemented so the use of mathematical notation when programming becomes natural.
Some particularities in this examples would be the indentation or the use of implicit typing. 
\vspace{0.5cm} 
\renewcommand{\home}{./Python/sources/Foundations/Algebra} 
\lstpython
\listings{\home/Matrix_operations.py}{def Matrix_operation_examples}
      {WARNING}{Matrix_operations.py} 








%_______________________________________________________________________________________________
\newpage  
\section{Dynamic allocation of vectors and matrices} 

Now let's use the square Vandermonde matrix  of $M\times M$:
$$
A_M =  \left[ a_{ M_{ij} } = \left( \frac{i}{M} \right)^{j-1}, \ \ i = 0, \ldots M-1, \ \  j=0, \ldots M-1 \right],  
$$
to compute the following operations:
$$ 
S = \sum_{M=1} ^{10} \Tr(A_M)  \qquad
S = \sum_{M=1} ^{5} \Tr(A_M^2) \qquad
S = \Tr \left( \sum_{k=0} ^{5} A_M^k  \right)  \qquad  M=8 
$$

Imagine now that the size of the matrix involved in your code is not known at compile-time, maybe it comes from 
an user input, 
an external file or 
it is the result of a previous operation. 
In this case, dynamic data objects are used so its memory storage (address, size, etc.) is allocated or modified during the execution of the program.
In Fortran for example the essential statements used to manage the memory are 
\texttt{allocate} and \texttt{deallocate} while the attribute for the data object is \texttt{allocatable}. 
The main properties of dynamic data objects are:

\begin{enumerate}
    \item The program decides how much memory reserve for a data objects so it can accommodate any size with no need of re-compiling the code.
    \item Modifications for the memory size are allowed. 
    \item It becomes the programmer responsibility to liberate the memory reserved for non-used arrays in order not to run out-of-memory.
    \item It is generally slower than static allocation. 
\end{enumerate}

The following examples, whether coded in Fortran or Python, are based on the following functions: 
\begin{itemize}[noitemsep]
    \item \texttt{Vandermonde( M )} which computes the Vandermonde matrix of a given dimension \texttt{M},
    \item \texttt{trace( A )} to compute the trace of a matrix and
    \item \texttt{power( a, k )}, a recursive function to obtain the $k$-th power of a matrix.
\end{itemize}
Once each function is coded, more general operations are easy to implement. 
In addition, remember that each abstraction can now be used in any program where this algebra is needed from now on. 




    \newpage 
    \subsection*{Fortran code}

The subroutine \texttt{Matrices\_allocation()} computes the mentioned operations in Fortran:
\lstfor
\renewcommand{\home}{./Fortran/sources/Foundations/Algebra} 
\listings{\home/Dynamic_allocation.f90}{subroutine Matrices_allocation}
{end subroutine}{Dynamic_allocation.f90}

Let's take a deeper look into the program. 
Notice that the 3-rank object \texttt{Ak} is declared with the attribute \texttt{allocatable} and colons \texttt{:} instead of the dimension specifications. 
Later, when the dimensions are known, the \texttt{allocate} function is used to reserve the appropriate memory for the variable.

For the first operation, the expression \texttt{trace( Vandermonde(M) )} is coded inside an implicit loop from 1 to 10. 
These results are constructed in a vector (using squared brackets) and 
\texttt{sum} performs the summation of the components of that vector. 
In addition, notice the use of few variables thanks to a declarative style. 
In an imperative style each Vandermonde matrix would be explicitly stored in a variable \texttt{AM(M,M)} and
their traces in a real vector variable used as an input for \texttt{sum} function. 
%Do not think that these objects are not used now, the compiler still needs them. 
%However, it automatically reserves memory, stores the intermediate results, returns only the single result needed \texttt{S} and, 
%when the calculation is finished, frees all that temporary memory used in an efficient way. 

The second operation is similar with the exception that now the trace is calculated on the product of two matrices. 
%Fortran, like any common scientific language already has implemented the product between two matrices of reals. 
A vector programming style has advantages to code algebra expressions as we know, 
but it also has a better performance when computing multiple operations if vector processors are used.
This is due to an increase in efficiency when the same operation is performed over a bunch of numbers. 

\newpage
For the third operation the variable \texttt{Ak} is dynamically allocated with bounds 0 to 5 in the third dimension. 
While normally the indices of any array starts in 1, the programmer may decide to modify it 
so the index automatically responds to a mathematical sense.
In this case, starting in 0, we allow \texttt{Ak(:,:,k)} to be a reference to the $k$-th power.
%with no need of remembering in which index starts and how many powers are we calculating. 
%If the needed powers of Vandermonde would only have been 4, 5 and 6, we could have allocated the matrix like: \texttt{allocate( Ak(8, 8, 4:6) )}. 
Finally, notice the complete array assignation performed with \texttt{Ak}. 
Once it is properly allocated, writing \texttt{Ak(:,:,k) =} is enough to store the result since it is previously known that the result is an $8\times8$ matrix. 
%Also, it is mandatory to specify to the function \texttt{sum} that the summation is only performed in the third dimension of \texttt{Ak} so it is adding one matrix to the next one. 

\vspace{0.5cm}
\listings{\home/Dynamic_allocation.f90}{function trace}
{end function}{Dynamic_allocation.f90}

\listings{\home/Dynamic_allocation.f90}{function power}
{end function}{Dynamic_allocation.f90}
For the functions \texttt{power( A, k )} and \texttt{trace( A )} two concepts should be extracted. 
Firstly, both must be used only with square matrices, where both mathematical operations are defined. 
Secondly, the concept of recursion is used to calculate the $k$-th power of a matrix. 
Essentially, the $k$-th power of a matrix is the multiplication of that matrix with his $k-1$-th power. 
A \texttt{recursive} statement is used in the declaration so the compiler knows that this function can call to itself to compute smaller instances of itself.
In this example it is going to compute the $k-1$-th power when trying to compute the $k$-th, 
the $k-2$-th power when trying to compute the $k-1$-th and so on until the identity matrix is reached (power 0). 



    \newpage
    \subsection*{Python code}
The same functions are written with Python in a similar style:
the use of implicit loops to construct arrays, 
the use of similar intrinsic functions or 
the need to define those functions not built-in in the language.
In this sense, the function \texttt{trace} belongs to the \texttt{numpy} library so there is no need to code it.

\vspace{0.5cm}
\lstpython
\renewcommand{\home}{./Python/sources/Foundations/Algebra} 
\listingsp{\home/Dynamic_allocation.py}{def Matrices_allocation}
{return}{Dynamic_allocation.py}

\listingsp{\home/Dynamic_allocation.py}{def power}
{matmul}{Dynamic_allocation.py}



\newpage
\section{Memories: Static, Heap, Stack}

It is clear that during the execution of the program certain amount of memory is needed. Data objects or the source code 
must be stored somewhere. The compiler, the linker and the operating system of the machine decides where each piece of data is stored. 
Three regions of the memory can be distinguished for a program (see Figure \ref{fig:Memories}): 
static, heap and stack, each one related to one type of allocation. Notice that the last two memories are dynamic in nature.

Static and dynamic allocation have been already treated. A third way to allocate memory size for data objects is used: 
stack (or automatic) allocation. The compiler is constantly using it 
in order to store temporary arrays used 
inside subroutines/functions or needed for array expressions.


\begin{figure}[h]
    \centering
    \includegraphics[width= \textwidth]{./doc/Figures/Memories.png}
    \caption{Three memory regions used by a program.}
    \label{fig:Memories}
\end{figure}

Let's revise some properties, advantages and problems associated to these memories:

\begin{itemize}
    \item \textbf{Static:} it is usually located in the low end of the memory reserved for the application. The compiler creates a list of variables to be allocated during compilation and gives them a fixed address 
    so the whole program can use these variables at any time and faster. 
    
    This static allocation requires knowing the amount of memory needed at compile-time.
    
    \item \textbf{Heap:} when a data object is allocated, the application requests an amount of memory to the system, if there is space available the system answers with the 
    starting address where storing the data. Once that memory is not needed any more, the program can ask the system to free that memory under the \texttt{deallocate} statement (in the case of Fortran) so
    that space becomes available for the next time. Notice that the amount of space for a program is bigger than the stack, but not unlimited, here concepts like virtual memory and swap play an important role. 
    
    For the heap a memory leak can happen if no deallocation is performed (the memory continue being used with not useful data) and it is normally slower than static allocation. 
    However, the programmer manages this space and the program decides how much memory to use for each purpose. 
    
    \item \textbf{Stack:} it is composed by a limited amount of memory and a pointer that holds the current position where routines can store local variables. This space is filled from the top to the bottom of the memory so any time that a subroutine or function (let's say \texttt{function A}) needs from temporary storage this space is used, the pointer is decremented and the stack space is reduced. If this function calls a nested \texttt{function B}, then its local variables are stored below variables of \texttt{A} and the pointer is decremented once again. Once the \texttt{routine B} finishes its operations, the pointer is incremented again below the spaced filled by \texttt{routine A} so that memory is available for the next routine. This structure is called LIFO; 'Last-In,-First-Out'.  
    
    The process is efficient and fast and the space is automatically freed when the routine returns to its host. This allocation is performed by the machine but the programmer usually has the option to declare some variables as \texttt{AUTOMATIC} in subprograms so they reside in the stack area. On the contrary, the amount of space is limited by the linker in the case of Windows and the programmer must be careful with allocating more space than it is available in order to avoid stack overflow. 
        
\end{itemize}


Stack overflow, when the memory allocated on the stack overflows into other memory regions, usually happens with two situations; extremely deep (or infinite) recursion and large array variables. 

%Primer ejemplo de stack overflow


The second example dynamically allocates a $400\times 400\times 400$ of 4-bytes reals array in the heap (\texttt{R})  but then the function \texttt{StackOverflow\_size( n )} tries to locate a similar automatic array (\texttt{S}) in the stack leading to a Stack Overflow error. 

\begin{verbatim}
real, allocatable :: R(:,:,:)
integer :: n

n = 400
allocate( R(n, n, n) )

R = StackOverflow_size( n ) 
\end{verbatim}

with the function:

\begin{verbatim}
function StackOverflow_size( n ) result(R)
integer, intent(in) :: n
real :: R(n, n, n)    

    R(:, :, :) = 1.

end function
\end{verbatim}

Some strategies can be used to avoid this error:

\begin{enumerate}
    \item Try to reduce the abuse of stack; allocate automatic arrays that usually goes to stack so they are located in heap. Then, they are automatically deallocated at the end of the routine. 
    
    \item The size of the Stack memory can be increased through a linker option. In Visual Studio for example it can be written: \texttt{/STACK:100000000} specifying the size in bytes desired.
    
    \item A compiler option can be used to change the default storing place for automatic arrays and temporary arrays so they are automatically located in the heap: \texttt{/heap-arrays}. If a kilobytes size is specified, only larger arrays are allocated to heap (i.e. \texttt{/heap-arrays100} to only affect arrays larger than 100 kilobytes). Use the value \texttt{0} to apply the behaviour to all arrays.  
    
\end{enumerate}


Now try to execute the second example with the option \texttt{/heap-arrays0} specified in the compilation options. For the case of Visual Studio it can be done in the project properties by clicking on Configuration Properties/Fortran/Command Line and adding that line.


%-------------------------------------------------------------------------------------------------------------
%MAYBE INTERESTING IN FUTURE:

%When using AUTOMATIC, SAVE, STATIC, etc.
%\item How to manage it in your program and recommendations.
%\item How to reserve more space in each of them.




%-------------------------------------------------------------------------------------------------------------
%Revise the following concepts:
%
%\begin{enumerate}
%    \item Who manages the memory.
%    \item Where are physically stored (RAM, swap).
%    \item Which is faster to allocate and use.
%    \item Common problems related to the use of that memory.
%    \item How to manage it in your program and recommendations.
%    \item How to reserve more space in each of them.
%    \item etc.
%\end{enumerate}


%  Fortran for example uses this memory to create space for local arrays (those based on arguments of routines) or for temporary copies in array expressions. 
%     the stack is managed by the CPU, there is no ability to modify it
% variables are allocated and freed automatically
%  
  